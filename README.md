# Sitio de Aprendizaje por Refuerzo - FIUBA 
En esta página se encuentra el contenido de la materia Aprendizaje por Refuerzo dictada por Julián Martínez durante el 1er cuatrimestre del 2020. 
El contenido de este curso dista mucho de ser definitivo y puede contener errores. La presentación de los temas tiene un sesgo parcial, desarrollando en algunas clases en mayor detalle la matemática necesaria, producto de mi formación como probabilista. Sin embargo, también intenté no dejar de lado la implementación computacional y el análisis de algunos casos simples de aplicación.

La mayor parte del contenido sigue de cerca los temas desarrollados (desde mi perspetiva) en los cursos de DeepMind de Reinforcement Learning del [2015](https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver) (David Silver) y del [2018](https://deepmind.com/learning-resources/reinforcement-learning-lectures-series-2018) (Hado van Hasselt). Producto de haber dado mayor detalle a algunas clases el temario recorrido fue menor. 

[Programa tentativo de la materia](https://github.com/julianfm7/cursoRL-FIUBA/blob/master/Programa-RL.pdf)

## [Videos](https://www.youtube.com/playlist?list=PLJRWzEGVolsKf7sWU2Myi_5To0x9ja9D9) 
Estos videos no fueron pensados con el propósito de realizar clases asincrónicas, las cuales se complementaban con reuniones semanales donde se discutían y/o detallaban las temáticas expuestas en torno a las preguntas que surgían. En particular la clase 2 es una clase sincrónica la cual fue grabada, quedando un tanto desordenada por lo que espero grabarla nuevamente en un futuro pero en el formato de los otros videos. A causa de esto no se encuentra disponible en youtube pero pueden escribirme solicitando acceso a la misma (julianfm7@gmail.com).

## Código y Slides
A lo largo de los videos se explica brevemente como utilizar Google Colab y como importar los notebooks que se usan en la clase, como también los que se propone completar a modo de ejercitación. Muchos de los ejemplos se desarrollan utilizando el toolkit [Gym](https://gym.openai.com/). 
Los notebooks y slides correspondientes a cada clase pueden encontrarse en este repositorio.

## Referencias y materiales varios

### Referencias principales
* Principal referencia: 
[Reinforcement Learning: An Introduction, Sutton and Barton](http://incompleteideas.net/book/the-book-2nd.html)

* Libro con más detalles matemáticos:
[Algorithms for Reinforcement Learning](https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf)

* [OpenAI Spinning Up](https://spinningup.openai.com/en/latest/user/introduction.html#what-this-is)

### Base de probabilidad
* [Construction of Stochastic Processes, Coupling and Regeneration; Pablo A. Ferrari, Antonio Galves](https://docs.ufpr.br/~lucambio/CE222/2S2011/oct2001.pdf)

* Pierre Bremaud; Markov chains: Gibbs fields, Monte Carlo simulation, and queues.

### Artículos interesantes/surveys
* Muchas cosas buenas y en general bien escritas sobre ML: [Foundations and Trends® in Machine Learning](https://www.nowpublishers.com/MAL) en particular las siguientes vinculados a la materia:

* [Introduction to Multi-Armed Bandits](https://www.nowpublishers.com/article/Details/MAL-068)

* [An Introduction to Deep Reinforcement Learning](https://www.nowpublishers.com/article/Details/MAL-071)

* [Bayesian Reinforcement Learning: A Survey](https://www.nowpublishers.com/article/Details/MAL-049)


##### Videos
* [Theory of Reinforcement Learning, Simons Insitute](https://simons.berkeley.edu/programs/rl20)


### Cursos varios
* [UCL Course on RL, David Silver](https://www.davidsilver.uk/teaching/)

* [DeepMind xUCL, Reinforcement Learning](https://deepmind.com/learning-resources/reinforcement-learning-lectures-series-2018)

* [CS 285 at UC Berkeley, Deep Reinforcement Learning](http://rail.eecs.berkeley.edu/deeprlcourse/)

### Python y RL
* [Repositorio dennybritz](https://github.com/aiot-tech/reinforcement-learning-David-Silver)

* [How to Think Like a ComputerScientist: Learning with Python 3](https://buildmedia.readthedocs.org/media/pdf/howtothink/latest/howtothink.pdf)

* [Deep Learning -  NYU](https://atcold.github.io/pytorch-Deep-Learning/)

* [Composing Programs](https://composingprograms.com/)

* [Automate the Boring Stuff with Python](https://automatetheboringstuff.com/)


Este sitio está construido utilizando [Jekyll](https://jekyllrb.com/), un pequeño motor que compila el sitio antes de publicarlo y nos permite "programar" algunas pequeñas cosas: usar variables, foreach, templates, vistas parciales, etc.
